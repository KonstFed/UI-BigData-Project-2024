{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48560fa7-aa36-4fb2-9967-c28ad0922555",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e64f8aa-e6f3-49b8-ac5d-e8f421fb131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from typing import List\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import torch\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9b4b6a-77df-47b4-9163-b3e5beaf1fc0",
   "metadata": {},
   "source": [
    "### Load HF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0131356-a409-4bc1-87f3-6ca453bdb319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-small-en-v1.5')\n",
    "model = AutoModel.from_pretrained('BAAI/bge-small-en-v1.5')\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def batch_embeddings(batch: List[str]):\n",
    "    encoded_input = tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        # Perform pooling. In this case, cls pooling.\n",
    "        sentence_embeddings = model_output[0][:, 0]\n",
    "    # normalize embeddings\n",
    "    sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
    "    return sentence_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fb9fa8-7a28-4f8f-9644-75aeda86b320",
   "metadata": {},
   "source": [
    "### Read anime ids and synopsises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "856ef760-921c-4817-9ef8-470857bdb598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warehouse = \"/user/team20/project/hive/warehouse\"\n",
    "team = \"team20\"\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"{} - spark ML\".format(team))\\\n",
    "        .master(\"yarn\")\\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://hadoop-02.uni.innopolis.ru:9883\")\\\n",
    "        .config(\"spark.sql.warehouse.dir\", warehouse)\\\n",
    "        .config(\"spark.sql.avro.compression.codec\", \"snappy\")\\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()\n",
    "spark.sql(\"USE team20_projectdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df0d1f23-43cf-4818-9b59-75303433659b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55087</td>\n",
       "      <td>the second season of rainbow ruby.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54648</td>\n",
       "      <td>a short anime series based on the game pokémon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54060</td>\n",
       "      <td>a plucky student stumbles upon the secret life...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53088</td>\n",
       "      <td>an animated music short featured on the variet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52992</td>\n",
       "      <td>mao otoha, who is now a second year high schoo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anime_id                                           synopsis\n",
       "0     55087                 the second season of rainbow ruby.\n",
       "1     54648  a short anime series based on the game pokémon...\n",
       "2     54060  a plucky student stumbles upon the secret life...\n",
       "3     53088  an animated music short featured on the variet...\n",
       "4     52992  mao otoha, who is now a second year high schoo..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df = spark.sql(\"SELECT id AS anime_id, synopsis FROM anime_part_buck WHERE synopsis != '-'\")\n",
    "df = spark_df.toPandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aeab0a-e8b4-40b3-b2e5-18f07224ca81",
   "metadata": {},
   "source": [
    "### Get anime embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6daf56d-8950-4acf-ba9a-b1e81e2b7f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11956815974d4c988b5fc7287ac4f368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4973 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 4\n",
    "synopsis_list = df['synopsis'].tolist()\n",
    "synopsis_embs = []\n",
    "\n",
    "for i in tqdm(range(0, len(synopsis_list) // batch_size)):\n",
    "    batch_synopsises = synopsis_list[i * batch_size:(i + 1) * batch_size]\n",
    "    batch_embs = batch_embeddings(batch_synopsises)\n",
    "    synopsis_embs.extend(batch_embs)\n",
    "\n",
    "if (i + 1) * batch_size < len(synopsis_list):\n",
    "    batch_synopsises = synopsis_list[(i + 1) * batch_size:len(synopsis_list)]\n",
    "    batch_embs = batch_embeddings(batch_synopsises)\n",
    "    synopsis_embs.extend(batch_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b1d250-fe1f-4616-8ffd-ce3415faf47c",
   "metadata": {},
   "source": [
    "### Write anime embeddings to csv om HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49b224dc-4484-4493-8618-6c80aae6427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(synopsis_embs) == len(synopsis_list), (len(synopsis_embs), len(synopsis_list))\n",
    "\n",
    "df['synopsis_emb'] = [emb.tolist() for emb in synopsis_embs]\n",
    "df.drop('synopsis', axis=1).to_csv('synopsis_embs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce241744-8ac6-4195-8dac-5492409c6a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put: `/user/team20/project/data/synopsis_embs.csv': File exists\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -put synopsis_embs.csv /user/team20/project/data/synopsis_embs.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5b2933-52ea-4cbc-9434-6be16d5668d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
