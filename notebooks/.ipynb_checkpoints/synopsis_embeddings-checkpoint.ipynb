{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48560fa7-aa36-4fb2-9967-c28ad0922555",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e64f8aa-e6f3-49b8-ac5d-e8f421fb131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from typing import List\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import torch\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9b4b6a-77df-47b4-9163-b3e5beaf1fc0",
   "metadata": {},
   "source": [
    "### Load HF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0131356-a409-4bc1-87f3-6ca453bdb319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-small-en-v1.5')\n",
    "model = AutoModel.from_pretrained('BAAI/bge-small-en-v1.5')\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def batch_embeddings(batch: List[str]):\n",
    "    encoded_input = tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        # Perform pooling. In this case, cls pooling.\n",
    "        sentence_embeddings = model_output[0][:, 0]\n",
    "    # normalize embeddings\n",
    "    sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
    "    return sentence_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fb9fa8-7a28-4f8f-9644-75aeda86b320",
   "metadata": {},
   "source": [
    "### Read anime ids and synopsises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "856ef760-921c-4817-9ef8-470857bdb598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warehouse = \"/user/team20/project/hive/warehouse\"\n",
    "team = \"team20\"\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"{} - spark ML\".format(team))\\\n",
    "        .master(\"yarn\")\\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://hadoop-02.uni.innopolis.ru:9883\")\\\n",
    "        .config(\"spark.sql.warehouse.dir\", warehouse)\\\n",
    "        .config(\"spark.sql.avro.compression.codec\", \"snappy\")\\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()\n",
    "spark.sql(\"USE team20_projectdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df0d1f23-43cf-4818-9b59-75303433659b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54252</td>\n",
       "      <td>what would you do if one of your family member...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52976</td>\n",
       "      <td>fleeing a traumatic childhood, lone mercenary ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51595</td>\n",
       "      <td>a strange and wonderful story about a special ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51048</td>\n",
       "      <td>a comedic short film by yoji kuri about runners.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50953</td>\n",
       "      <td>the kingdom of metallicana is under attack fro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anime_id                                           synopsis\n",
       "0     54252  what would you do if one of your family member...\n",
       "1     52976  fleeing a traumatic childhood, lone mercenary ...\n",
       "2     51595  a strange and wonderful story about a special ...\n",
       "3     51048   a comedic short film by yoji kuri about runners.\n",
       "4     50953  the kingdom of metallicana is under attack fro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df = spark.sql(\"SELECT id AS anime_id, synopsis FROM anime_part_buck WHERE synopsis != '-'\")\n",
    "df = spark_df.toPandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aeab0a-e8b4-40b3-b2e5-18f07224ca81",
   "metadata": {},
   "source": [
    "### Get anime embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6daf56d-8950-4acf-ba9a-b1e81e2b7f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea94d8c9cc92443da4df6657c8f0bb3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4973 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e155b5aafa54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mbatch_synopsises\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msynopsis_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynopsis_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mbatch_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_synopsises\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0msynopsis_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_embs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-5c602fe53c70>\u001b[0m in \u001b[0;36mbatch_embeddings\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbatch_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mencoded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2470\u001b[0m                 \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2473\u001b[0m             )\n\u001b[1;32m   2474\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2661\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2662\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2663\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2664\u001b[0m         )\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;31m# we add an overflow_to_sample_mapping array (see below)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0msanitized_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens_and_encodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0mstack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens_and_encodings\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0msanitized_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "synopsis_list = df['synopsis'].tolist()\n",
    "synopsis_embs = []\n",
    "\n",
    "for i in tqdm(range(0, len(synopsis_list) // batch_size)):\n",
    "    batch_synopsises = synopsis_list[i * batch_size:(i + 1) * batch_size]\n",
    "    batch_embs = batch_embeddings(batch_synopsises)\n",
    "    synopsis_embs.extend(batch_embs)\n",
    "\n",
    "if (i + 1) * batch_size < len(synopsis_list):\n",
    "    batch_synopsises = synopsis_list[(i + 1) * batch_size:len(synopsis_list)]\n",
    "    batch_embs = batch_embeddings(batch_synopsises)\n",
    "    synopsis_embs.extend(batch_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b1d250-fe1f-4616-8ffd-ce3415faf47c",
   "metadata": {},
   "source": [
    "### Write anime embeddings to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49b224dc-4484-4493-8618-6c80aae6427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(synopsis_embs) == len(synopsis_list), (len(synopsis_embs), len(synopsis_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5635aae-674c-4f43-a3ab-a3f69729fed7",
   "metadata": {},
   "source": [
    "### Find user embeddings by averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eff5090-389d-4f59-9e9f-5b1dd18eb995",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.sql(\"SELECT id AS anime_id, synopsis FROM anime_part_buck WHERE synopsis != '-'\")\n",
    "scores_df = spark_df.toPandas()\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6191f0e6-c2b2-4fe3-b9fc-acf9c1d1b7c3",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3add6e1d-b530-4293-a90f-3f3ec9061ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentences we want sentence embeddings for\n",
    "sentences = [\"\"\"after a horrific alchemy experiment goes wrong in the elric household, brothers edward and alphonse are left in a catastrophic new reality. ignoring the alchemical principle banning human transmutation, the boys attempted to bring their recently deceased mother back to life. instead, they suffered brutal personal loss: alphonse's body disintegrated while edward lost a leg and then sacrificed an arm to keep alphonse's soul in the physical realm by binding it to a hulking suit of armor.\n",
    "the brothers are rescued by their neighbor pinako rockbell and her granddaughter winry. known as a bio-mechanical engineering prodigy, winry creates prosthetic limbs for edward by utilizing \"automail,\" a tough, versatile metal used in robots and combat armor. after years of training, the elric brothers set off on a quest to restore their bodies by locating the philosopher's stoneâ€”a powerful gem that allows an alchemist to defy the traditional laws of equivalent exchange.\n",
    "as edward becomes an infamous alchemist and gains the nickname \"fullmetal,\" the boys' journey embroils them in a growing conspiracy that threatens the fate of the world.\"\"\",\n",
    "             \"\"\"eccentric scientist rintarou okabe has a never-ending thirst for scientific exploration. together with his ditzy but well-meaning friend mayuri shiina and his roommate itaru hashida, rintarou founds the future gadget laboratory in the hopes of creating technological innovations that baffle the human psyche. despite claims of grandeur, the only notable \"gadget\" the trio have created is a microwave that has the mystifying power to turn bananas into green goo.\n",
    "however, when rintarou decides to attend neuroscientist kurisu makise's conference on time travel, he experiences a series of strange events that lead him to believe that there is more to the \"phone microwave\" gadget than meets the eye. apparently able to send text messages into the past using the microwave, rintarou dabbles further with the \"time machine,\" attracting the ire and attention of the mysterious organization sern.\n",
    "due to the novel discovery, rintarou and his friends find themselves in an ever-present danger. as he works to mitigate the damage his invention has caused to the timeline, he is not only fighting a battle to save his loved ones, but also one against his degrading sanity.\"\"\"]\n",
    "\n",
    "print(\"Sentence embeddings:\", batch_embeddings(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e01b4708-2fd7-4501-ba76-9a672ebc7a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ebf19f80bf4198b55abeaf41a35626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    _ = batch_embeddings(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce241744-8ac6-4195-8dac-5492409c6a41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
